[SERVER]
host = 127.0.0.1
port = 55002
max_connections = 2

[TRANSLATION]
# 英日翻訳用のモデル名（Hugging Faceのモデル名）
model_name_en_ja = staka/fugumt-en-ja
# 日英翻訳用のモデル名（Hugging Faceのモデル名）
model_name_ja_en = staka/fugumt-ja-en
# 使用デバイス: auto（自動選択）、cpu、cuda、mps（Apple Silicon）
device = cpu
# GPU ID（cudaデバイス使用時のみ有効）: 0, 1, 2... または auto（自動選択）
gpu_id = auto
# 最大翻訳文字数（トークン数の上限）
max_length = 512
# ビームサーチの幅（大きいほど翻訳品質向上、処理時間増加）
num_beams = 4
# 生成温度（1.0=標準、低いほど保守的、高いほど創造的）
temperature = 1.0
# モデルキャッシュの使用（trueで高速化、falseで最新状態）
use_cache = true
# FP16（半精度浮動小数点）モード（trueでメモリ使用量削減、処理速度向上）
use_fp16 = false

[LOGGING]
level = INFO
file = logs/fugumt_translator.log
max_size = 10MB
backup_count = 5

[PERFORMANCE]
# バッチサイズ（同時に処理する翻訳リクエスト数、大きいほど効率的だがメモリ使用量増加）
batch_size = 1
# タイムアウト時間（秒）（翻訳処理の最大待ち時間）
timeout_seconds = 30.0
# ワーカースレッド数（並行処理数、CPUコア数に合わせて調整）
worker_threads = 4
