[SERVER]
host = 127.0.0.1
port = 55001
max_connections = 2

[TRANSLATION]
# 英日翻訳用のモデル名（Hugging Faceのモデル名）
model_name_en_ja = staka/fugumt-en-ja
# 日英翻訳用のモデル名（Hugging Faceのモデル名）
model_name_ja_en = staka/fugumt-ja-en
# 使用デバイス: auto（自動選択）、cpu、cuda、mps（Apple Silicon）
device = cpu
# GPU ID（cudaデバイス使用時のみ有効）: 0, 1, 2... または auto（自動選択）
gpu_id = auto
# 最大翻訳文字数（トークン数の上限）
max_length = 128
# ビームサーチの幅（大きいほど翻訳品質向上、処理時間増加）
# 同時に探索する翻訳候補の数（多様な表現から最適解を選択）
# 値が大きいほど翻訳品質が向上するが、計算時間とメモリ使用量が増加する
# 一般的には1-8の範囲で、4は品質と処理速度のバランスが良い設定
num_beams = 4
# 生成温度（1.0=標準、低いほど保守的、高いほど創造的）
# 翻訳生成時のランダム性を制御する温度パラメータ（文体の多様性に影響）
# 低い値（0.5-0.8）は安定した翻訳、高い値（1.2-1.5）は創造的だが不安定
# 1.0は標準設定で、一般的な翻訳タスクに適したバランスの良い値
temperature = 0.5
# モデルキャッシュの使用（trueで高速化、falseで最新状態）
# 計算結果をキャッシュして再利用するかの設定（処理速度に大きく影響）
# trueで同じ入力の翻訳結果を再利用し高速化、falseで毎回新規計算
# 一般的にはtrueを推奨（メモリ使用量は増加するが処理速度が大幅向上）
use_cache = true
# FP16（半精度浮動小数点）モード（trueでメモリ使用量削減、処理速度向上）
# 半精度浮動小数点（16bit）による高速化機能（GPU使用時のみ有効）
# trueでメモリ使用量半減・処理速度向上、falseで標準精度（32bit）維持
# 翻訳品質への影響は軽微だが、古いGPUでは対応していない場合がある
use_fp16 = true

[LOGGING]
level = INFO
file = logs/fugumt_translator.log
max_size = 10MB
backup_count = 5

[PERFORMANCE]
# タイムアウト時間（秒）（翻訳処理の最大待ち時間）
timeout_seconds = 30.0
# ワーカースレッド数（WebSocket並行処理数）
worker_threads = 2
